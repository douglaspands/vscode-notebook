{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EXTRAÇÃO DE MANGA PELO SITE MANGALIVRE"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup\n",
    "\n",
    "### Dependencias do SO\n",
    "É necessario fazer a instalação das seguintes dependencias do SO Linux (Ubuntu):\n",
    "1) Instale o Google Chrome\n",
    "```sh\n",
    "sudo apt-get install -y curl unzip xvfb libxi6 libgconf-2-4 && \\\n",
    "    wget https://dl.google.com/linux/direct/google-chrome-stable_current_amd64.deb && \\\n",
    "    sudo apt install ./google-chrome-stable_current_amd64.deb -y && \\\n",
    "    google-chrome --version\n",
    "```\n",
    "2) Instale o Chromedriver baseado na versão no Google-Chrome. Nesse momento a versão é a `108.0.5359.71`:\n",
    "```sh\n",
    "wget https://chromedriver.storage.googleapis.com/108.0.5359.71/chromedriver_linux64.zip && \\\n",
    "    unzip chromedriver_linux64.zip && \\\n",
    "    sudo mv chromedriver /usr/bin/chromedriver && \\\n",
    "    sudo chown root:root /usr/bin/chromedriver && \\\n",
    "    sudo chmod +x /usr/bin/chromedriver\n",
    "```\n",
    "> - [https://chromedriver.chromium.org/](https://chromedriver.chromium.org/)\n",
    "\n",
    "### Dependencias do Python\n",
    "```sh\n",
    "poetry add pydash selenium-wire\n",
    "```"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## WebDriver + MangaLivre"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import annotations\n",
    "\n",
    "import traceback\n",
    "import base64\n",
    "from uuid import uuid4\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from selenium.webdriver.chrome.webdriver import WebDriver\n",
    "from seleniumwire.webdriver import Chrome\n",
    "from seleniumwire.request import Request\n",
    "from selenium.webdriver.common.by import By\n",
    "from pathlib import Path\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "import requests\n",
    "from pydash import py_\n",
    "\n",
    "FILE_PATH = Path(\"./files\")\n",
    "\n",
    "\n",
    "def salvar_tela(webdriver: WebDriver):\n",
    "    file_path = str(FILE_PATH.resolve().joinpath(f\"prints/{uuid4()!s}.png\"))\n",
    "    webdriver.save_screenshot(file_path)\n",
    "    print(f\">> print {webdriver.current_url=} / {file_path=}\")\n",
    "\n",
    "\n",
    "class ChromeWebDriver:\n",
    "    WINDOW_SIZE = \"1920x1080\"  # \"1366x768\"\n",
    "\n",
    "    def __init__(self, implicitly_wait: int = 0, headers: dict[str, str] = None):\n",
    "        self._webdriver: WebDriver = None\n",
    "        self._implicitly_wait = implicitly_wait\n",
    "        self._headers = {}\n",
    "        if headers and isinstance(headers, dict):\n",
    "            self._headers.update(headers)\n",
    "        self._options = Options()\n",
    "        prefs = {\n",
    "            \"download.default_directory\": str(FILE_PATH.resolve()),\n",
    "            \"download.prompt_for_download\": False,\n",
    "            \"directory_upgrade\": True,\n",
    "            \"safebrowsing.enabled\": True,\n",
    "        }\n",
    "        self._options.add_experimental_option(\"prefs\", prefs)\n",
    "        self._options.add_experimental_option(\n",
    "            \"excludeSwitches\", [\"load-extension\", \"enable-automation\"]\n",
    "        )\n",
    "        self._options.add_argument(\"--disable-extensions\")\n",
    "        self._options.add_argument(\"--headless\")\n",
    "        self._options.add_argument(\"--no-sandbox\")\n",
    "        # self._options.add_argument(\"--disable-dev-shm-usage\")\n",
    "        self._options.add_argument(\"window-size=\" + \",\".join(self.WINDOW_SIZE.split(\"x\")))  # self._options.add_argument(\"window-size=1366,768\")\n",
    "\n",
    "    def __enter__(self) -> WebDriver:\n",
    "        return self.webdriver\n",
    "\n",
    "    def __exit__(self, exc_type, exc_value, exc_traceback) -> None:\n",
    "        if exc_type:\n",
    "            print(\"\".join(traceback.format_exception(exc_type, exc_value, exc_traceback)))\n",
    "        self.quit()\n",
    "        self.__del__()\n",
    "\n",
    "    def __del__(self) -> None:\n",
    "        del self\n",
    "\n",
    "    def _interceptor(self, request: Request):\n",
    "        for hk, hv in self._headers.items():\n",
    "            if request.headers.get(hk):\n",
    "                del request.headers[hk]\n",
    "            request.headers[hk] = hv\n",
    "\n",
    "    @property\n",
    "    def webdriver(self) -> WebDriver:\n",
    "        if not self._webdriver:\n",
    "            self._webdriver = Chrome(\"chromedriver\", options=self._options)\n",
    "            self._webdriver.request_interceptor = self._interceptor\n",
    "            if self._implicitly_wait:\n",
    "                self._webdriver.implicitly_wait(self._implicitly_wait)\n",
    "        return self._webdriver\n",
    "\n",
    "    def quit(self):\n",
    "        if self._webdriver:\n",
    "            self._webdriver.quit()\n",
    "\n",
    "\n",
    "class MangaPagina:\n",
    "    def __init__(self, manga_capitulo_id: int, numero: int, imagem: bytes, extensao: str):\n",
    "        self.numero = numero\n",
    "        self.imagem = imagem\n",
    "        self.extensao = extensao\n",
    "        self.manga_capitulo_id = manga_capitulo_id\n",
    "        self.id = id(self)\n",
    "\n",
    "    def __str__(self) -> str:\n",
    "        return f\"<MangaPagina id='{self.id!s}'>\"\n",
    "\n",
    "    def __repr__(self) -> str:\n",
    "        return str(self)\n",
    "\n",
    "\n",
    "class MangaCapitulo:\n",
    "    def __init__(self, nome: str, capitulo: str, qtde_paginas: int = 0):\n",
    "        self.nome = nome\n",
    "        self.capitulo = capitulo\n",
    "        self.qtde_paginas = qtde_paginas\n",
    "        self.id = id(self)\n",
    "        self.paginas: list[MangaPagina] = []\n",
    "\n",
    "    def __str__(self) -> str:\n",
    "        return f\"<MangaCapitulo id='{self.id!s}'>\"\n",
    "        \n",
    "    def __repr__(self) -> str:\n",
    "        return str(self)\n",
    "\n",
    "    def adicionar_pagina(self, pagina: MangaPagina):\n",
    "        self.paginas.append(pagina)\n",
    "        \n",
    "    def pagina_em_html(self, numero_pagina: int = 1) -> str:\n",
    "        b64 = base64.b64encode(self.paginas[numero_pagina-1].imagem).decode(\"utf-8\")        \n",
    "        return f'<img src=\"data:image/{self.paginas[numero_pagina-1].extensao};base64,{b64}\"/>'\n",
    "        \n",
    "    @property\n",
    "    def _nome_arquivo(self) -> str:\n",
    "        return py_.camel_case(f\"{self.nome} {self.capitulo}\")\n",
    "\n",
    "    def gerar_cbz(self):\n",
    "        nome_arquivo = self._nome_arquivo + \".cbz\"\n",
    "        temp_path = FILE_PATH.resolve().joinpath(self._nome_arquivo)\n",
    "        file_path = FILE_PATH.resolve().joinpath(nome_arquivo)\n",
    "        temp_path.mkdir()\n",
    "        for pagina in self.paginas:\n",
    "            pagina_path = str(temp_path.joinpath(\"PAG-\" + str(pagina.numero).zfill(3) + \".\" + pagina.extensao))\n",
    "            with open(pagina_path, \"wb\") as fout:\n",
    "                fout.write(pagina.imagem)\n",
    "        temp_path.rmdir()\n",
    "        print(f\"Arquivo *.cbz gerado em: {file_path}\")\n",
    "\n",
    "    def gerar_pdf(self):\n",
    "        nome_arquivo = self._nome_arquivo + \".pdf\"\n",
    "        temp_path = FILE_PATH.resolve().joinpath(self._nome_arquivo)\n",
    "        file_path = FILE_PATH.resolve().joinpath(nome_arquivo)\n",
    "        temp_path.mkdir()\n",
    "        for pagina in self.paginas:\n",
    "            pagina_path = str(temp_path.joinpath(\"PAG-\" + str(pagina.numero).zfill(3) + \".\" + pagina.extensao))\n",
    "            with open(pagina_path, \"wb\") as fout:\n",
    "                fout.write(pagina.imagem)\n",
    "        temp_path.rmdir()\n",
    "        print(f\"Arquivo *.cbz gerado em: \")\n",
    "\n",
    "\n",
    "class MangaLivre:\n",
    "    DELAY = 10\n",
    "    \n",
    "    def __init__(self):\n",
    "        self._chrome_webdriver = ChromeWebDriver(implicitly_wait=self.DELAY)\n",
    "\n",
    "    def _obter_scans(self, url: str) -> dict[int, str]:\n",
    "        with self._chrome_webdriver as webdriver:\n",
    "            pagina = {}\n",
    "            xpath_image = '//div[@class=\"manga-image\"]/picture/img'\n",
    "            xpeth_next = '//div[@class=\"page-next\"]'\n",
    "            webdriver.get(url)\n",
    "            num_pag = 1\n",
    "            while True:\n",
    "                if \"#comments\" in webdriver.current_url:\n",
    "                    break\n",
    "                elem = webdriver.find_element(By.XPATH, xpath_image)\n",
    "                img_src = elem.get_attribute(\"src\")\n",
    "                pagina[str(num_pag).zfill(3)][\"raw\"] = requests.get(img_src).content\n",
    "                pagina[str(num_pag).zfill(3)][\"ext\"] = img_src.split(\".\").pop()\n",
    "                webdriver.find_element(By.XPATH, xpeth_next).click()\n",
    "                num_pag += 1\n",
    "        return pagina\n",
    "\n",
    "    def extrair_manga(self, nome: str, url: str) -> MangaCapitulo:\n",
    "        capitulo = url.split(\"/\").pop()\n",
    "        pag_scans = self._obter_scans(url)\n",
    "        manga = MangaCapitulo(nome=nome, capitulo=capitulo, qtde_paginas=len(list(pag_scans.keys())))\n",
    "        for pag, img in pag_scans.items():\n",
    "            pagina = MangaPagina(manga_capitulo_id=manga.id, numero=int(pag), imagem=img[\"raw\"], extensao=img[\"ext\"])\n",
    "            manga.adicionar_pagina(pagina)\n",
    "        return manga\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extração"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mangalivre = MangaLivre()\n",
    "manga = mangalivre.extrair_manga(\n",
    "    nome=\"One Punch Man\",\n",
    "    url=\"https://mangalivre.net/ler/one-punch-man/online/428424/211\",\n",
    ")\n",
    "manga"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython import display\n",
    "\n",
    "display.HTML(manga.pagina_em_html(13))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Desenvolvimento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "manga.paginas[5].imagens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chrome_webdriver = ChromeWebDriver()\n",
    "webdriver = chrome_webdriver.webdriver\n",
    "webdriver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "webdriver.get(\"https://mangalivre.net/ler/one-punch-man/online/428424/211\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SCROLL_PAUSE_TIME = 0.5\n",
    "\n",
    "last_height = webdriver.execute_script(\"return document.body.scrollHeight\")\n",
    "\n",
    "while True:\n",
    "    webdriver.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n",
    "    time.sleep(SCROLL_PAUSE_TIME)\n",
    "    new_height = webdriver.execute_script(\"return document.body.scrollHeight\")\n",
    "    if new_height == last_height:\n",
    "        break\n",
    "    last_height = new_height\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "salvar_tela(webdriver)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xpath_image = '//div[@class=\"manga-image\"]/picture/img'\n",
    "images = []\n",
    "for elem in webdriver.find_elements(By.XPATH, xpath_image):\n",
    "    images.append(elem.get_attribute(\"src\"))\n",
    "    salvar_tela(webdriver)\n",
    "images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "webdriver.quit()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "6c5ca7531f59fa0228d3041ec16587b2d14eed0a831b158ef3a275f8b2515388"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
